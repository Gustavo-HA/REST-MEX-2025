{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'preprocessing' from 'c:\\\\Users\\\\Gus\\\\Documents\\\\proyectos\\\\REST-MEX-2025\\\\src\\\\preprocessing.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tqdm\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import shutil\n",
    "\n",
    "from argparse import Namespace\n",
    "arg = Namespace()\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if os.path.abspath(\"../src\") not in sys.path:\n",
    "    sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "import preprocessing as pp\n",
    "import config\n",
    "import importlib\n",
    "\n",
    "importlib.reload(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Town",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d6872b89-1c95-4ba2-bb28-0a55d14c1aa9",
       "rows": [
        [
         "0",
         "Mi Lugar Favorito!!!!",
         "Excelente lugar para comer y pasar una buena noche!!!\nEl servicio es de primera y la comida exquisita!!!",
         "5.0",
         "Sayulita",
         "Nayarit",
         "Restaurant"
        ],
        [
         "1",
         "lugares interesantes para visitar",
         "andar mucho, así que un poco difícil para personas con niños pequeños, pero con mucha historia en la zona, y la diversión de aprender un poco de todo, y explorar las ruinas. La playa también era bastante agradable!",
         "4.0",
         "Tulum",
         "QuintanaRoo",
         "Attractive"
        ],
        [
         "2",
         "No es el mismo Dreams ",
         "Es nuestra cuarta visita a Dreams Tulum, elegimos este hotel para festejar mi cumpleaños ya que en este hotel nos comprometimos y casamos y tenemos un cariño muy especial por este lugar, pero mostramos que cambiaron las cosas.  En cuestión de instalaciones sigue perfecto!! La playa muy limpia a pesar del sargazo ( es una cuestión natural incontrolable).   Pero en la amabilidad y servicio que los distinguía lo han perdido bastante, los empleados andan corriendo por todos lados, gritando de un lado a otro tratando de organizarse y pasamos varios detalles como por ejemplo mi esposo pidió un juego verde y la mesera le contestó que se parara él que estaba en la esquina porque solo se llevaba el café!! Eso jamás hubiera pasado en el Dreams de antes!!! Cuando uno se topaba al staff del",
         "3.0",
         "Tulum",
         "QuintanaRoo",
         "Hotel"
        ],
        [
         "3",
         "un buen panorama cerca de CancÃºn",
         "Estando en CancÃºn, fuimos al puerto y tomamos un Ferry a la Isla Mujeres.....despuÃ©s de un corto viaje, llegamos a esta pequeÃ±a isla, donde todo el mundo se desplaza en moto, carritos de golf, bicicleta o simplemente caminando.La recorrimos durante un rato y terminamos en la Playa Norte, donde pasamos la tarde recostadas sobre la arena y baÃ±Ã¡ndonos en el mar...... el agua tiene muy poca profundidad, por lo que puedes adentrarte mucho en el mar simplemente caminando.Si estÃ¡s en CancÃºn, te recomiendo destinar medio dÃ­a para conocer esta simpÃ¡tica isla.",
         "4.0",
         "Isla_Mujeres",
         "QuintanaRoo",
         "Attractive"
        ],
        [
         "4",
         "El mejor",
         "Es un lugar antiguo y por eso me encanto tiene un área de juegos gigante en la cual hay boliche, ping pong, mesas de cartas, dominó. Esta super céntrico Pase ahí año nuevo y la fiesta fue increíble También te prestan bicis para que visites la ciudad",
         "5.0",
         "Patzcuaro",
         "Michoacan",
         "Hotel"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Town</th>\n",
       "      <th>Region</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi Lugar Favorito!!!!</td>\n",
       "      <td>Excelente lugar para comer y pasar una buena n...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sayulita</td>\n",
       "      <td>Nayarit</td>\n",
       "      <td>Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lugares interesantes para visitar</td>\n",
       "      <td>andar mucho, así que un poco difícil para pers...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Tulum</td>\n",
       "      <td>QuintanaRoo</td>\n",
       "      <td>Attractive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No es el mismo Dreams</td>\n",
       "      <td>Es nuestra cuarta visita a Dreams Tulum, elegi...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Tulum</td>\n",
       "      <td>QuintanaRoo</td>\n",
       "      <td>Hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>un buen panorama cerca de CancÃºn</td>\n",
       "      <td>Estando en CancÃºn, fuimos al puerto y tomamos...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Isla_Mujeres</td>\n",
       "      <td>QuintanaRoo</td>\n",
       "      <td>Attractive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El mejor</td>\n",
       "      <td>Es un lugar antiguo y por eso me encanto tiene...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Patzcuaro</td>\n",
       "      <td>Michoacan</td>\n",
       "      <td>Hotel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title  \\\n",
       "0              Mi Lugar Favorito!!!!   \n",
       "1  lugares interesantes para visitar   \n",
       "2             No es el mismo Dreams    \n",
       "3  un buen panorama cerca de CancÃºn   \n",
       "4                           El mejor   \n",
       "\n",
       "                                              Review  Polarity          Town  \\\n",
       "0  Excelente lugar para comer y pasar una buena n...       5.0      Sayulita   \n",
       "1  andar mucho, así que un poco difícil para pers...       4.0         Tulum   \n",
       "2  Es nuestra cuarta visita a Dreams Tulum, elegi...       3.0         Tulum   \n",
       "3  Estando en CancÃºn, fuimos al puerto y tomamos...       4.0  Isla_Mujeres   \n",
       "4  Es un lugar antiguo y por eso me encanto tiene...       5.0     Patzcuaro   \n",
       "\n",
       "        Region        Type  \n",
       "0      Nayarit  Restaurant  \n",
       "1  QuintanaRoo  Attractive  \n",
       "2  QuintanaRoo       Hotel  \n",
       "3  QuintanaRoo  Attractive  \n",
       "4    Michoacan       Hotel  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv(config.TRAIN_FILE)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_set.drop(columns=config.TARGETS)\n",
    "y1 = train_set[config.TARGET1] # Polarity\n",
    "y2 = train_set[config.TARGET2] # Town\n",
    "y3 = train_set[config.TARGET3] # Type\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.2, random_state=42, stratify=y1)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size=0.2, random_state=42, stratify=y2)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X, y3, test_size=0.2, random_state=42, stratify=y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train = pp.pp_pipeline.fit_transform(X3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Texto_Limpio",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5107e441-2099-4b03-99a2-ffd682bc9d33",
       "rows": [
        [
         "52557",
         "tan maravill jueg disneyland lleg azulik tod experient lug magic record visit disneyland habit arbol respet naturalez com cocktails er nivel lug perfect ir parej graci azulik"
        ],
        [
         "706",
         "visit isla janitzi maravill ir descubr hermos isla definit pued pasartel genial local viend artesani disfrut beb com"
        ],
        [
         "75004",
         "desayun estupend frut tortit huev ofrec dol favorit gran ambient complacient seleccion frut"
        ],
        [
         "6629",
         "excelent cad vez visit oblig cad vez vam sayulit gran surt sals pued aplic opcion carn parrill personal encant sals crem bistec gorgonzol upper pontoon bistec ala parrill increibl encant desayun genial bat amabil dueñ personalmas"
        ],
        [
         "200700",
         "hotel agrad excelent ubic desayun gratis bonit lug aloj mientr realiz tod atraccion alrededor palenqu personal hotel agrad hotel habit limpi piscin divert niñ buen maner refresc restaur genial desayun bien preci ubic estupend camin restaur centr unic quej luk duch calient consegu agu calient mejor tercer noch probabl culp tra atencion dud aloj aqu nuev recomiend tripadvisor dic desayun gratis desayun gratis dijeron recepcion dic problem asesor viaj"
        ],
        [
         "50586",
         "fin seman ixtapal lug maravill verdader joy escond com fresc preci competit servici sobresalient recom encarecid lug orient famili delici plat"
        ],
        [
         "134966",
         "asad puerc mas ric viern abril entram lug conoc part vei teni air acondicion lug bonit limpi general meser toc trat bien casi habi gent lug mes ped casuel asad puerc frijol mol casuel chicharron verd famili coincid delici dieron totop salsit sabros general llev buen experienciamas"
        ],
        [
         "13297",
         "val pen entorn entorn impresion puert just teotihuac gust com pens degust gamey estupend si quier gamey restaur centr autent aliment fiel estil guacamol vien cortez cerd frit lug patat frit ped conej encant ped plat cerd pens decent tercer orden carner aka liam decid carner estil limon fantast especial despues larg sol mañan teotihuac general experient bonit recomendablemas"
        ],
        [
         "4155",
         "unas vist impresion precios ubic hic excursion gui lueg explor cuent excursion ayud entend siti may recomend mund familiariz histori usar gui impresion"
        ],
        [
         "116006",
         "cuart estanci cas quetzal ambient agrad entorn tranquil segur bonit jardin piscin desayun inclu opcion si dese buen servici suficient lej ciud suficient cerc ir andand valladol vec aloj hotel pequeñ vec vam ir alli nuev proxim vez"
        ],
        [
         "52811",
         "mejor lug isla mujer lug maravill ambient relaj com beb delici extraordinari atencion equip trabaj siempr atent divert educ esper regres pront"
        ],
        [
         "84625",
         "ideal visit fin seman larg hosped cabañ experient realment buen dos habit dos cam matrimonial comedor cocin sof bañ complet acogedor limpi ideal ir famili descans restaur servici buffet fin seman dias festiv ric buen preci atencion personal excelent recepcion restaur hotel bien ubic relat cerc centr zacatlan excelent opcion ir fin seman famili visit casc tulim vall piedr encim"
        ],
        [
         "41711",
         "pintoresc call empedr exclus peaton merc artesan comerci local pued encontr ques diferent tip artesan etc plaz iglesi merc local"
        ],
        [
         "83094",
         "encant mejor bloody marys mund bar man daniel majisim guacamol gourmet mejor personal atent"
        ],
        [
         "192818",
         "sueñ budist increibl santuari verd palabr describ experient"
        ],
        [
         "56707",
         "com ador buen preci visit restaur meson marqu despues leer recomend agrad cen personal amabl entorn agrad buen com preci estupend x plat principal postr x x x cervez beb aperit pruebalomas"
        ],
        [
         "37915",
         "cerc jardin pequeñ gran hotel habit ampli cam enorm limpi trat exquisit personal agradec car sonrient desayun continental cumpl piscin limpi apetec encuentr poc distanci mts jardin ingles lug recomend pas dias relax to the max"
        ],
        [
         "37157",
         "fuert pequeñ bonit entrad pes si mal recuerd si local entrad doming gratis entrad mural tomart fot pirat aun alto banc podert asom recorr tomart fot dentr fuert"
        ],
        [
         "204433",
         "increibl increibl cenot agu sup cristalin temperatur ideal nad cenot subterrane cevern huec entra reflej sol estupend adem comercial hac mas barat entrad much men gent ik kil"
        ],
        [
         "9996",
         "mejor tempor sol visit almuerz tard tempor advert visit mejor tempor critic mencion monton construccion evident culp restaur principi servicioal client permit men client podr ser mejor rechaz servici acerc restaur camarer pregunt si quer beb traves gest plaz afuer dijeron pregunt si pod sent dentr dij asient interior huesped com sol vez explic alli com acogedor ped sop pesc encant camaron import ajo com da mar poll mol mar gust dieron cortes patat frit dos sals roj verd gre ensal tortill pan mantequill chocolat flan bonit mar ped margarit gran ped cocacol vez termin cocacol nadi ofrec pregunt si quer beb com dolar propin general aun asi recomend beb aun fantast favorit ensal verd organ sop pesc sol lug mejor tempor altamas"
        ],
        [
         "165253",
         "com excelent lug pas bien atencion destac aliment bien trag x mejor"
        ],
        [
         "73232",
         "visit cortit alquil aut mejor opcion conoc qued despu play sol pued ver acces play años atras entrad ofrec parqu conozc suen pur negoci barat"
        ],
        [
         "99103",
         "buen com local vim cocin cen cervez fri menu divert leer com buen servici buen oli hum ah buen aun lug regres"
        ],
        [
         "67982",
         "atencion famili seman pas dan atencion excelent especial recepcion paol mil felicit pendient famili orden buen desayun general lug agrad"
        ],
        [
         "171424",
         "aniversari ampli varied mixolog com delici especial curry servici atencion excelent"
        ],
        [
         "61194",
         "centric ubic bien equip lleg mision grand tras agot viaj hor palenqu alivi pod parart cam comod despues tom duch necesari lueg sal noch ciud call paralel hotel vehicul domest peaton disfrut escen nocturn restaur bar tiend orient turism cuadr hotel plaz central ciud conviert agrad pase com restaur hotel much altern tentador are inmediat pared adorn tel enmarc ejempl local calid muse lug relaj gratif aloj"
        ],
        [
         "55736",
         "ir muse leccion histori gran encontr acerc origen loret especial interes ten sid educ jesuit"
        ],
        [
         "188112",
         "bien conserv si lind dentr impresion catedral hermos llam atencion hermos color mas lind dentr catedral sup recarg dej visit val pen"
        ],
        [
         "69693",
         "ruin bien conserv visit tulum deb dec ruin bien conserv deb prev cos siguient entrad pag pes acept moned tampoc tarjet credit apart cerc atm retir diner si lleg alli pes cas qued mas remedi pag servici gui cobr entrad mas servici gui albert atiend bien conoc histori ciud aunqu cre suced invent cos mejor document visit ruin si dej llev gui dan mate dec venezuel excursion dur mas minut deb usted ped exig gui llev tod zon expliqu asi molest pag habl ruin si bien conserv cuid lug tranquil respir much tranquil llev agu calor intens vend adentr parec genial exist vendedor molest siti visit entrad estacion ruin sol mts pued hac camin trencit llev ultim cost"
        ],
        [
         "130235",
         "fabul cre monton restaur isla embarg mang caf taxi si biciclet si situ cerc principal terminal ferry mejor favorit servici maravill tacosd pesc mor hibiscus beb ron refresc hac tiemp alli recuerd si ron hibisc delici ademas barri ador pas vist lad isla impresionantesmas"
        ],
        [
         "21796",
         "excelent ambient buen rap atencion part luis carl aliment ric buen music excelent ambient"
        ],
        [
         "35986",
         "lind buenisim pas refrescart rat pas tom fot herm agu cristalin formacion roc color bell hermos lug"
        ],
        [
         "109640",
         "buen hotel hotel encuentr selv bonit instal bastant buen cuart grand limpi buen air acondicion piscin grand restaur bufet desayun grand buen opcion gran varied"
        ],
        [
         "132408",
         "lug ensueñ vist mil comentari decid public mes despues lug sid maravill aqu propus matrimoni novi excelent aliment servici pued dec lug volv dud graci rol hab apoy sal maravill"
        ],
        [
         "149152",
         "servici pobr ped sandwich vegetal patat frit dieron poll despues esper casi minut recib adecu novi termin com camarer olvid patat frit traj clar estabansobr cocin correos camarer pid disculp vez buen experienciamas"
        ],
        [
         "126487",
         "guau cenot unic ahor asi pued compar increibl agu fri refresc pequeñ pec nad usted cuev murcielag espeluzn form divert gui asi se cuest dij traig gaf moneder becausec abaj rob"
        ],
        [
         "155127",
         "estupend siti mod com asi darl oportun content hab hech concurr ultim noch asi problem esper pon nombr list marc temporal camin par puert tom unacop bar com buen aperit increibl servici rap agrad hac sup buen margarit servici ingles español necesit merec pen cen alli monton opcion menu ingles españolmas"
        ],
        [
         "67054",
         "pued perd mang desayun almuerz exit menu ir pequeñ asi ten pacienci val pen esper pintoresc off the beat path monton gent pierd oportunidadd irmas"
        ],
        [
         "188359",
         "buen com preci just com delici much opcion menu preci just calid asient air libr agrad unic cos molest servidor dirij pequeñ niñ parec irrespetu muj clar adult"
        ],
        [
         "184043",
         "pesadill tip tard hor registr confund segu hac llam telefon segu dic hotel noch sigu abriend expedi medianoch despues hor viaj ugh entonc habit suci colchon suci"
        ],
        [
         "89075",
         "lun visit inclus si lun visit indispens df llen millon person visit dan ide importanciaalquil taxi priv pes hor alrededor hor aproxim hor minut dan preci pesostambien alquil gui bilingü pes pas hor buenohay monton tiend vent ten cuent silv monton imitaciones general buen viaj conductor priv usted necesit esper nadi"
        ],
        [
         "6024",
         "ciud real san cristobal cas bonit hotel excelent ubic habit ampli lind decor unic gust restaur desayun incluid tours inici tempran desayun list dijeron am dia noch pens cen ahi nadi atend comensal viend part futbol termin nadi acerc invit sent esper mientr decid cen lug"
        ],
        [
         "44922",
         "servicial honest lug bastant agrad limpi cuestion econom bastant acces compar demas hotel dec servici particul olvid dos cos personal hic lleg amabl hac much graci recomend salud famili quinter castellan"
        ],
        [
         "123655",
         "jug fresc cevich favorit cevich tac pesc parrill guacamol acompañ fresc jug hech agu champan servici buen habl ingles tom vis amabl preci razon com esconsistent buen condiment ir tac fresc mantien recipient limpi siempr ocup vec esper mes minut abiert sol almuerzomas"
        ],
        [
         "51659",
         "agrad si gust histori novi visit tulum viaj cancun combin xel si hac combin tan bien cuid dan tiemp tulum si tom tiemp entrar parqu tiemp limit ademas recomend sal gui turist tan pront lleg ruin llev tiemp habl hech podr hab leid pantall ruin sol minut explor tiend fresc entrad inclu fotograf leon beb mon part divert hac tom gener cantid fotograf celul dolar leon dolar bien emple preparat sol calor camp abiert grum sudor ruin guay ver gust ten tiemp"
        ],
        [
         "46737",
         "visit lug magic increibl lug disfrut clim sol pas maravill"
        ],
        [
         "19286",
         "tan impresion anunc gui viaj situ cas buen restaur mayor ruin yucatan"
        ],
        [
         "127100",
         "mejor com lug destru cad plat nach vid tac sencillez clav decor pued sent impid com call com asientod plastic impresion menu complet confus carn cerd asi sugier orden nach guacamol vien chips carn maiz quesed tac ques tac ques harin dos coron autent fiest preci buenomas"
        ],
        [
         "189779",
         "com fantast nuev regres isla quer volv olivi content hab hech excelent cen aperit vari grieg cerez hel caser termin especial buen servici excelent ambient asegurat hac reserv asi queestan vuelt jardin hac cen maravillosamas"
        ],
        [
         "137945",
         "visit cenot zaci cenot ubic cuadr centr bastant econom natural restaur pec dan terapi limpi piern cosquill incluidasj ja ja verd bien sal relaj restaur muymas"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 166440
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto_Limpio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52557</th>\n",
       "      <td>tan maravill jueg disneyland lleg azulik tod e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>visit isla janitzi maravill ir descubr hermos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75004</th>\n",
       "      <td>desayun estupend frut tortit huev ofrec dol fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6629</th>\n",
       "      <td>excelent cad vez visit oblig cad vez vam sayul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200700</th>\n",
       "      <td>hotel agrad excelent ubic desayun gratis bonit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77286</th>\n",
       "      <td>total perd disfrut asi dirig cancun chich itza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50959</th>\n",
       "      <td>normal ser numer tripadvisor esper cos mal ve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7066</th>\n",
       "      <td>mejor mexican cenot simplement increibl hesist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145830</th>\n",
       "      <td>sueñ realid resort inclu simplement increibl p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25125</th>\n",
       "      <td>servici fantast com beb fantast servici inmejo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166440 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Texto_Limpio\n",
       "52557   tan maravill jueg disneyland lleg azulik tod e...\n",
       "706     visit isla janitzi maravill ir descubr hermos ...\n",
       "75004   desayun estupend frut tortit huev ofrec dol fa...\n",
       "6629    excelent cad vez visit oblig cad vez vam sayul...\n",
       "200700  hotel agrad excelent ubic desayun gratis bonit...\n",
       "...                                                   ...\n",
       "77286   total perd disfrut asi dirig cancun chich itza...\n",
       "50959   normal ser numer tripadvisor esper cos mal ve ...\n",
       "7066    mejor mexican cenot simplement increibl hesist...\n",
       "145830  sueñ realid resort inclu simplement increibl p...\n",
       "25125   servici fantast com beb fantast servici inmejo...\n",
       "\n",
       "[166440 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([X3_train, y3_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer TFIDF\n",
    "arg.tfidf_max_features = 5000\n",
    "arg.tfidf_ngram_range = (1, 2)\n",
    "arg.token_pattern=r'(?u)\\b[^\\d\\W]+\\b'\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=arg.tfidf_max_features, \n",
    "                                   ngram_range=arg.tfidf_ngram_range, \n",
    "                                   token_pattern=arg.token_pattern)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos en un Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class restaurantDataset(Dataset):\n",
    "    def __init__(self, data : pd.DataFrame, vectorizer, label_encoder,\n",
    "                 y : str, standardize = False):\n",
    "        \"\"\"\n",
    "        Initializes the restaurantDataset class.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): The input dataframe containing the text and labels.\n",
    "            vectorizer (TfidfVectorizer): The TF-IDF vectorizer to transform text data.\n",
    "            label_encoder (LabelEncoder): The label encoder to transform labels into numerical format.\n",
    "            y (str): The column name in the dataframe representing the target labels.\n",
    "            use_pca (bool, optional): Whether to apply PCA for dimensionality reduction. Default is False.\n",
    "            pca (PCA, optional): The PCA object to use for dimensionality reduction. Required if use_pca is True.\n",
    "            n_components (int, optional): The number of principal components to retain if PCA is applied. Default is 3.\n",
    "\n",
    "        Attributes:\n",
    "            data (pd.DataFrame): The input dataframe.\n",
    "            n_samples (int): The number of samples in the dataset.\n",
    "            X (torch.Tensor): The transformed feature matrix (TF-IDF or PCA-reduced).\n",
    "            y (torch.Tensor): The transformed target labels.\n",
    "            fitted_pca (PCA or None): The fitted PCA object if PCA is applied, otherwise None.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.n_samples = len(data)\n",
    "        \n",
    "        # Transform text to TF-IDF vectors\n",
    "        tfidf_matrix = vectorizer.transform(data[config.NEW_COLUMN])\n",
    "        self.X = torch.tensor(tfidf_matrix.toarray(), dtype=torch.float32)\n",
    "\n",
    "        if standardize:\n",
    "            scaler = StandardScaler()\n",
    "            self.X_np = self.X.numpy()\n",
    "            self.X = torch.tensor(scaler.fit_transform(self.X_np), dtype=torch.float32)\n",
    "        \n",
    "        # Transform labels to numbers\n",
    "        self.y = torch.tensor(label_encoder.fit_transform(data[y]),\n",
    "                              dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg.standardize = True\n",
    "arg.y = \"Type\"\n",
    "\n",
    "tfidf_vectorizer.fit(df3[config.NEW_COLUMN])\n",
    "type_label_encoder = LabelEncoder()\n",
    "\n",
    "dataset = restaurantDataset(df3, tfidf_vectorizer, type_label_encoder, arg.y,\n",
    "                            arg.standardize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del train set 133152\n",
      "Longitud del test set 33288\n",
      "Shape of X [N, C]: torch.Size([128, 5000]) torch.float32\n",
      "Shape of y: torch.Size([128]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Separamos en conjuntos de entrenamiento y de prueba.\n",
    "arg.random_state = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.X, dataset.y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=arg.random_state,\n",
    "                                                    stratify=dataset.y)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_data = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "print(\"Longitud del train set\", len(train_data))\n",
    "print(\"Longitud del test set\", len(test_data))\n",
    "\n",
    "# Dataloaders\n",
    "arg.batch_size = 128\n",
    "train_dataloader = DataLoader(train_data, batch_size=arg.batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=arg.batch_size)\n",
    "\n",
    "for i, (X, y) in enumerate(test_dataloader):\n",
    "    print(f\"Shape of X [N, C]: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer modelo - Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "TfidfClassifier(\n",
      "  (fc1): Linear(in_features=5000, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class TfidfClassifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size=3, dropout=0.3):\n",
    "        super(TfidfClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        logits = self.fc3(x)\n",
    "        return logits\n",
    "\n",
    "arg.dropout = 0.2\n",
    "arg.lr = 0.01\n",
    "model = TfidfClassifier(input_size=5000, dropout=arg.dropout).to(device)\n",
    "print(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=arg.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\"\n",
    "    Entrena el modelo con los datos del dataloader y actualiza los pesos del modelo.\n",
    "    \n",
    "    Inputs:\n",
    "    - dataloader: DataLoader con los datos de entrenamiento.\n",
    "    - model: Modelo a entrenar.\n",
    "    - loss_fn: Función de pérdida.\n",
    "    - optimizer: Optimizador.\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return 100*correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint_path, filename=\"checkpoint.pth\",\n",
    "                    best_filename=\"model_best.pth\"):\n",
    "    \"\"\"\n",
    "    Save the model checkpoint to the specified path.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The state of the model to save, typically includes model weights and optimizer state.\n",
    "        is_best (bool): If True, saves a copy of the checkpoint as \"model_best.pth\".\n",
    "        checkpoint_path (str): The directory where the checkpoint will be saved.\n",
    "        filename (str): The name of the checkpoint file. Default is \"checkpoint.pth\".\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(checkpoint_path, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint_path, best_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "arg.lr = 1e-2\n",
    "arg.epochs = 100\n",
    "arg.patience = 20\n",
    "\n",
    "# Scheduler hyperparameters\n",
    "arg.lr_patience = 10\n",
    "arg.lr_factor = 0.5 # Se reduce el learning rate a la mitad cada 10 epochs\n",
    "# sin mejorar el desempeño\n",
    "\n",
    "# Saving directory\n",
    "arg.savedir = \"../model\"\n",
    "os.makedirs(arg.savedir, exist_ok=True)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode = \"max\",\n",
    "    patience=arg.lr_patience,\n",
    "    factor=arg.lr_factor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.098794  [  128/133152]\n",
      "loss: 0.288518  [12928/133152]\n",
      "loss: 0.263353  [25728/133152]\n",
      "loss: 0.145743  [38528/133152]\n",
      "loss: 0.210210  [51328/133152]\n",
      "loss: 0.113453  [64128/133152]\n",
      "loss: 0.277052  [76928/133152]\n",
      "loss: 0.193696  [89728/133152]\n",
      "loss: 0.302888  [102528/133152]\n",
      "loss: 0.275967  [115328/133152]\n",
      "loss: 0.221592  [128128/133152]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.229724 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.290687  [  128/133152]\n",
      "loss: 0.200542  [12928/133152]\n",
      "loss: 0.198060  [25728/133152]\n",
      "loss: 0.054287  [38528/133152]\n",
      "loss: 0.159539  [51328/133152]\n",
      "loss: 0.069764  [64128/133152]\n",
      "loss: 0.449665  [76928/133152]\n",
      "loss: 0.099574  [89728/133152]\n",
      "loss: 0.555347  [102528/133152]\n",
      "loss: 0.409924  [115328/133152]\n",
      "loss: 0.295210  [128128/133152]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.773888 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.660970  [  128/133152]\n",
      "loss: 0.349860  [12928/133152]\n",
      "loss: 0.284247  [25728/133152]\n",
      "loss: 0.152965  [38528/133152]\n",
      "loss: 0.548563  [51328/133152]\n",
      "loss: 0.248700  [64128/133152]\n",
      "loss: 0.437514  [76928/133152]\n",
      "loss: 0.263357  [89728/133152]\n",
      "loss: 0.413506  [102528/133152]\n",
      "loss: 0.518996  [115328/133152]\n",
      "loss: 0.445420  [128128/133152]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.583550 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.580417  [  128/133152]\n",
      "loss: 0.264320  [12928/133152]\n",
      "loss: 0.316840  [25728/133152]\n",
      "loss: 0.199272  [38528/133152]\n",
      "loss: 0.221040  [51328/133152]\n",
      "loss: 0.280428  [64128/133152]\n",
      "loss: 1.051651  [76928/133152]\n",
      "loss: 0.287329  [89728/133152]\n",
      "loss: 0.400391  [102528/133152]\n",
      "loss: 0.343500  [115328/133152]\n",
      "loss: 0.363744  [128128/133152]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 1.185005 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.458673  [  128/133152]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     tuning_metric = test(test_dataloader, model, criterion)\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# Update the scheduler\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dataloader, model, loss_fn, optimizer)\u001b[39m\n\u001b[32m     18\u001b[39m loss = loss_fn(pred, y)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m optimizer.step()\n\u001b[32m     23\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gus\\miniconda3\\envs\\restmex\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gus\\miniconda3\\envs\\restmex\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gus\\miniconda3\\envs\\restmex\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "best_metric = 0\n",
    "n_no_improve = 0\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, criterion, optimizer)\n",
    "    tuning_metric = test(test_dataloader, model, criterion)\n",
    "    \n",
    "    # Update the scheduler\n",
    "    scheduler.step(tuning_metric)\n",
    "    \n",
    "    # Save model checkpoint\n",
    "    is_best = tuning_metric > best_metric\n",
    "    if is_best:\n",
    "        best_metric = tuning_metric\n",
    "        n_no_improve = 0\n",
    "    else:\n",
    "        n_no_improve += 1\n",
    "    \n",
    "    save_checkpoint({\n",
    "        \"epoch\": t + 1,\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"best_metric\": best_metric,\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }, is_best, arg.savedir, \n",
    "                    filename=\"checkpoint_on_stemm_5000_tfidf.pth\", \n",
    "                    best_filename=\"model-best_on_stemm_5000_tfidf.pth\")\n",
    "    \n",
    "    if n_no_improve >= arg.patience:\n",
    "        print(\"No improvement. Breaking out of loop.\")\n",
    "        break\n",
    "    \n",
    "print(\"Ya quedó.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Attractive       0.95      0.96      0.95     11187\n",
      "       Hotel       0.95      0.92      0.93      8226\n",
      "  Restaurant       0.95      0.96      0.95     13875\n",
      "\n",
      "    accuracy                           0.95     33288\n",
      "   macro avg       0.95      0.95      0.95     33288\n",
      "weighted avg       0.95      0.95      0.95     33288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = OneVsRestClassifier(LogisticRegression(max_iter=1000, solver=\"liblinear\"))\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=type_label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gus\\miniconda3\\envs\\restmex\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# Parámetro de complejidad del SVM, se proponen estos\n",
    "# y se recorrerán con GridSearch\n",
    "parameters = {\"C\": [.05, .12, .25, .5, 1, 2, 4]}   \n",
    "# Tratar de penalizar con base a la proporción de ejemplos\n",
    "# en cada clase\n",
    "svr = svm.LinearSVC(class_weight='balanced', max_iter=10000)\n",
    "grid = GridSearchCV(estimator=svr, param_grid=parameters,\n",
    "                     n_jobs=6, scoring=\"f1_macro\", cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(f\"F1-score: {f1_score(y_test, y_pred, pos_label='1'):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "restmex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
