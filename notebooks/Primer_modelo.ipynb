{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import shutil\n",
    "\n",
    "from argparse import Namespace\n",
    "arg = Namespace()\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if os.path.abspath(\"../src\") not in sys.path:\n",
    "    sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "import preprocessing as pp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Town",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "28d54fb4-2a1c-48a6-88f7-44f08f2bbb92",
       "rows": [
        [
         "0",
         "Mi Lugar Favorito!!!!",
         "Excelente lugar para comer y pasar una buena noche!!!\nEl servicio es de primera y la comida exquisita!!!",
         "5.0",
         "Sayulita",
         "Nayarit",
         "Restaurant"
        ],
        [
         "1",
         "lugares interesantes para visitar",
         "andar mucho, así que un poco difícil para personas con niños pequeños, pero con mucha historia en la zona, y la diversión de aprender un poco de todo, y explorar las ruinas. La playa también era bastante agradable!",
         "4.0",
         "Tulum",
         "QuintanaRoo",
         "Attractive"
        ],
        [
         "2",
         "No es el mismo Dreams ",
         "Es nuestra cuarta visita a Dreams Tulum, elegimos este hotel para festejar mi cumpleaños ya que en este hotel nos comprometimos y casamos y tenemos un cariño muy especial por este lugar, pero mostramos que cambiaron las cosas.  En cuestión de instalaciones sigue perfecto!! La playa muy limpia a pesar del sargazo ( es una cuestión natural incontrolable).   Pero en la amabilidad y servicio que los distinguía lo han perdido bastante, los empleados andan corriendo por todos lados, gritando de un lado a otro tratando de organizarse y pasamos varios detalles como por ejemplo mi esposo pidió un juego verde y la mesera le contestó que se parara él que estaba en la esquina porque solo se llevaba el café!! Eso jamás hubiera pasado en el Dreams de antes!!! Cuando uno se topaba al staff del",
         "3.0",
         "Tulum",
         "QuintanaRoo",
         "Hotel"
        ],
        [
         "3",
         "un buen panorama cerca de CancÃºn",
         "Estando en CancÃºn, fuimos al puerto y tomamos un Ferry a la Isla Mujeres.....despuÃ©s de un corto viaje, llegamos a esta pequeÃ±a isla, donde todo el mundo se desplaza en moto, carritos de golf, bicicleta o simplemente caminando.La recorrimos durante un rato y terminamos en la Playa Norte, donde pasamos la tarde recostadas sobre la arena y baÃ±Ã¡ndonos en el mar...... el agua tiene muy poca profundidad, por lo que puedes adentrarte mucho en el mar simplemente caminando.Si estÃ¡s en CancÃºn, te recomiendo destinar medio dÃ­a para conocer esta simpÃ¡tica isla.",
         "4.0",
         "Isla_Mujeres",
         "QuintanaRoo",
         "Attractive"
        ],
        [
         "4",
         "El mejor",
         "Es un lugar antiguo y por eso me encanto tiene un área de juegos gigante en la cual hay boliche, ping pong, mesas de cartas, dominó. Esta super céntrico Pase ahí año nuevo y la fiesta fue increíble También te prestan bicis para que visites la ciudad",
         "5.0",
         "Patzcuaro",
         "Michoacan",
         "Hotel"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Town</th>\n",
       "      <th>Region</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi Lugar Favorito!!!!</td>\n",
       "      <td>Excelente lugar para comer y pasar una buena n...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sayulita</td>\n",
       "      <td>Nayarit</td>\n",
       "      <td>Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lugares interesantes para visitar</td>\n",
       "      <td>andar mucho, así que un poco difícil para pers...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Tulum</td>\n",
       "      <td>QuintanaRoo</td>\n",
       "      <td>Attractive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No es el mismo Dreams</td>\n",
       "      <td>Es nuestra cuarta visita a Dreams Tulum, elegi...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Tulum</td>\n",
       "      <td>QuintanaRoo</td>\n",
       "      <td>Hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>un buen panorama cerca de CancÃºn</td>\n",
       "      <td>Estando en CancÃºn, fuimos al puerto y tomamos...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Isla_Mujeres</td>\n",
       "      <td>QuintanaRoo</td>\n",
       "      <td>Attractive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El mejor</td>\n",
       "      <td>Es un lugar antiguo y por eso me encanto tiene...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Patzcuaro</td>\n",
       "      <td>Michoacan</td>\n",
       "      <td>Hotel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title  \\\n",
       "0              Mi Lugar Favorito!!!!   \n",
       "1  lugares interesantes para visitar   \n",
       "2             No es el mismo Dreams    \n",
       "3  un buen panorama cerca de CancÃºn   \n",
       "4                           El mejor   \n",
       "\n",
       "                                              Review  Polarity          Town  \\\n",
       "0  Excelente lugar para comer y pasar una buena n...       5.0      Sayulita   \n",
       "1  andar mucho, así que un poco difícil para pers...       4.0         Tulum   \n",
       "2  Es nuestra cuarta visita a Dreams Tulum, elegi...       3.0         Tulum   \n",
       "3  Estando en CancÃºn, fuimos al puerto y tomamos...       4.0  Isla_Mujeres   \n",
       "4  Es un lugar antiguo y por eso me encanto tiene...       5.0     Patzcuaro   \n",
       "\n",
       "        Region        Type  \n",
       "0      Nayarit  Restaurant  \n",
       "1  QuintanaRoo  Attractive  \n",
       "2  QuintanaRoo       Hotel  \n",
       "3  QuintanaRoo  Attractive  \n",
       "4    Michoacan       Hotel  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/Rest-Mex_2025_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un buen panorama cerca de CancÃºn\n",
      "un buen panorama cerca de Cancún\n"
     ]
    }
   ],
   "source": [
    "# Arregla los mojibakes\n",
    "print(df[\"Title\"].iloc[3])\n",
    "df['Title'] = df['Title'].fillna('').apply(pp.arregla_mojibake)\n",
    "df['Review'] = df['Review'].fillna('').apply(pp.arregla_mojibake)\n",
    "print(df[\"Title\"].iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quita stopwords\n",
    "df['Texto_Limpio'] = (df['Title'].fillna('') + ' ' + df['Review'].fillna('')).apply(pp.quita_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Texto_Limpio",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8f9b24b5-0ea1-4683-a74b-a1cd702187fd",
       "rows": [
        [
         "0",
         "lugar favorito excelente lugar comer pasar buena noche servicio primera comida exquisita",
         "Restaurant"
        ],
        [
         "1",
         "lugares interesantes visitar andar así difícil personas niños pequeños mucha historia zona diversión aprender explorar ruinas playa bastante agradable",
         "Attractive"
        ],
        [
         "2",
         "mismo dreams cuarta visita dreams tulum elegimos hotel festejar cumpleaños hotel comprometimos casamos cariño especial lugar mostramos cambiaron cosas cuestión instalaciones sigue perfecto playa limpia pesar sargazo cuestión natural incontrolable amabilidad servicio distinguía perdido bastante empleados andan corriendo lados gritando lado tratando organizarse pasamos varios detalles ejemplo esposo pidió juego verde mesera contestó parara esquina solo llevaba café jamás pasado dreams topaba staff",
         "Hotel"
        ],
        [
         "3",
         "buen panorama cerca cancún cancún puerto tomamos ferry isla mujeresdespués corto viaje llegamos pequeña isla mundo desplaza moto carritos golf bicicleta simplemente caminandola recorrimos rato terminamos playa norte pasamos tarde recostadas arena bañándonos mar agua poca profundidad puedes adentrarte mar simplemente caminandosi cancún recomiendo destinar medio día conocer simpática isla",
         "Attractive"
        ],
        [
         "4",
         "mejor lugar antiguo encanto área juegos gigante boliche ping pong mesas cartas dominó super céntrico pase ahí año nuevo fiesta increíble prestan bicis visites ciudad",
         "Hotel"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto_Limpio</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lugar favorito excelente lugar comer pasar bue...</td>\n",
       "      <td>Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lugares interesantes visitar andar así difícil...</td>\n",
       "      <td>Attractive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mismo dreams cuarta visita dreams tulum elegim...</td>\n",
       "      <td>Hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buen panorama cerca cancún cancún puerto tomam...</td>\n",
       "      <td>Attractive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mejor lugar antiguo encanto área juegos gigant...</td>\n",
       "      <td>Hotel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Texto_Limpio        Type\n",
       "0  lugar favorito excelente lugar comer pasar bue...  Restaurant\n",
       "1  lugares interesantes visitar andar así difícil...  Attractive\n",
       "2  mismo dreams cuarta visita dreams tulum elegim...       Hotel\n",
       "3  buen panorama cerca cancún cancún puerto tomam...  Attractive\n",
       "4  mejor lugar antiguo encanto área juegos gigant...       Hotel"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targetType = pd.concat([df[\"Texto_Limpio\"], df[\"Type\"]], axis = 1)\n",
    "df_targetType.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Attractive' 'Hotel' 'Restaurant']\n"
     ]
    }
   ],
   "source": [
    "# Label Encoder\n",
    "le = LabelEncoder()\n",
    "le.fit(df_targetType[\"Type\"])\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abajo', 'abierta', 'abierto', ..., 'único', 'único inconveniente',\n",
       "       'únicos'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorizer TFIDF\n",
    "arg.tfidf_max_features = 2500\n",
    "arg.tfidf_ngram_range = (1, 2)\n",
    "arg.token_pattern=r'(?u)\\b[^\\d\\W]+\\b'\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=arg.tfidf_max_features, \n",
    "                                   ngram_range=arg.tfidf_ngram_range, \n",
    "                                   token_pattern=arg.token_pattern)\n",
    "tfidf_vectorizer.fit(df_targetType[\"Texto_Limpio\"])\n",
    "tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos en un Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class restaurantDataset(Dataset):\n",
    "    def __init__(self, data : pd.DataFrame, vectorizer, label_encoder,\n",
    "                 y : str, use_pca = False, pca = None, n_components = 3):\n",
    "        \"\"\"\n",
    "        Initializes the restaurantDataset class.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): The input dataframe containing the text and labels.\n",
    "            vectorizer (TfidfVectorizer): The TF-IDF vectorizer to transform text data.\n",
    "            label_encoder (LabelEncoder): The label encoder to transform labels into numerical format.\n",
    "            y (str): The column name in the dataframe representing the target labels.\n",
    "            use_pca (bool, optional): Whether to apply PCA for dimensionality reduction. Default is False.\n",
    "            pca (PCA, optional): The PCA object to use for dimensionality reduction. Required if use_pca is True.\n",
    "            n_components (int, optional): The number of principal components to retain if PCA is applied. Default is 3.\n",
    "\n",
    "        Attributes:\n",
    "            data (pd.DataFrame): The input dataframe.\n",
    "            n_samples (int): The number of samples in the dataset.\n",
    "            X (torch.Tensor): The transformed feature matrix (TF-IDF or PCA-reduced).\n",
    "            y (torch.Tensor): The transformed target labels.\n",
    "            fitted_pca (PCA or None): The fitted PCA object if PCA is applied, otherwise None.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.n_samples = len(data)\n",
    "        \n",
    "        # Transform text to TF-IDF vectors\n",
    "        tfidf_matrix = vectorizer.transform(data[\"Texto_Limpio\"])\n",
    "\n",
    "        if use_pca:\n",
    "            pca.fit(tfidf_matrix.toarray())\n",
    "            self.X = torch.tensor(pca.transform(tfidf_matrix.toarray()), dtype=torch.float32)\n",
    "            self.fitted_pca = pca\n",
    "        else:\n",
    "            self.X = torch.tensor(tfidf_matrix.toarray(), dtype=torch.float32)\n",
    "            self.fitted_pca = None\n",
    "        \n",
    "        # Transform labels to numbers\n",
    "        self.y = torch.tensor(label_encoder.transform(data[y]),\n",
    "                              dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg.use_pca = True\n",
    "arg.pca_n_components = 3\n",
    "arg.pca = PCA(n_components=arg.pca_n_components)\n",
    "\n",
    "dataset = restaurantDataset(df_targetType, tfidf_vectorizer, le,\n",
    "                               use_pca=arg.use_pca, pca=arg.pca,\n",
    "                               n_components=arg.pca_n_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del train set 166440\n",
      "Longitud del test set 41611\n",
      "Shape of X [N, C]: torch.Size([128, 3]) torch.float32\n",
      "Shape of y: torch.Size([128]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Separamos en conjuntos de entrenamiento y de prueba.\n",
    "arg.random_state = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.X, dataset.y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=arg.random_state,\n",
    "                                                    stratify=dataset.y)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_data = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "print(\"Longitud del train set\", len(train_data))\n",
    "print(\"Longitud del test set\", len(test_data))\n",
    "\n",
    "# Dataloaders\n",
    "arg.batch_size = 128\n",
    "train_dataloader = DataLoader(train_data, batch_size=arg.batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=arg.batch_size)\n",
    "\n",
    "for i, (X, y) in enumerate(test_dataloader):\n",
    "    print(f\"Shape of X [N, C]: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer modelo - Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "PrimerModelo(\n",
      "  (fc1): Linear(in_features=3, out_features=8, bias=True)\n",
      "  (fc2): Linear(in_features=8, out_features=6, bias=True)\n",
      "  (fc3): Linear(in_features=6, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class PrimerModelo(nn.Module):\n",
    "    def __init__(self, input_size, output_size=3):\n",
    "        super(PrimerModelo, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 8)\n",
    "        self.fc2 = nn.Linear(8, 6)\n",
    "        self.fc3 = nn.Linear(6, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        logits = self.fc3(x)\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "model = PrimerModelo(input_size=3).to(device)\n",
    "print(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\"\n",
    "    Entrena el modelo con los datos del dataloader y actualiza los pesos del modelo.\n",
    "    \n",
    "    Inputs:\n",
    "    - dataloader: DataLoader con los datos de entrenamiento.\n",
    "    - model: Modelo a entrenar.\n",
    "    - loss_fn: Función de pérdida.\n",
    "    - optimizer: Optimizador.\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return 100*correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint_path, filename=\"checkpoint.pth\",\n",
    "                    best_filename=\"model_best.pth\"):\n",
    "    \"\"\"\n",
    "    Save the model checkpoint to the specified path.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The state of the model to save, typically includes model weights and optimizer state.\n",
    "        is_best (bool): If True, saves a copy of the checkpoint as \"model_best.pth\".\n",
    "        checkpoint_path (str): The directory where the checkpoint will be saved.\n",
    "        filename (str): The name of the checkpoint file. Default is \"checkpoint.pth\".\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(checkpoint_path, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint_path, best_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gus\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training hyperparameters\n",
    "arg.lr = 2.3e-1\n",
    "arg.epochs = 100\n",
    "arg.patience = 20\n",
    "\n",
    "# Scheduler hyperparameters\n",
    "arg.lr_patience = 10\n",
    "arg.lr_factor = 0.5 # Se reduce el learning rate a la mitad cada 10 epochs\n",
    "# sin mejorar el desempeño\n",
    "\n",
    "# Saving directory\n",
    "arg.savedir = \"../model\"\n",
    "os.makedirs(arg.savedir, exist_ok=True)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode = \"max\",\n",
    "    patience=arg.lr_patience,\n",
    "    factor=arg.lr_factor,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.095197  [  128/166440]\n",
      "loss: 0.573864  [12928/166440]\n",
      "loss: 0.384915  [25728/166440]\n",
      "loss: 0.340853  [38528/166440]\n",
      "loss: 0.378220  [51328/166440]\n",
      "loss: 0.424934  [64128/166440]\n",
      "loss: 0.456884  [76928/166440]\n",
      "loss: 0.367751  [89728/166440]\n",
      "loss: 0.325119  [102528/166440]\n",
      "loss: 0.422908  [115328/166440]\n",
      "loss: 0.361905  [128128/166440]\n",
      "loss: 0.391873  [140928/166440]\n",
      "loss: 0.389938  [153728/166440]\n",
      "loss: 0.238898  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.349103 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.396965  [  128/166440]\n",
      "loss: 0.399555  [12928/166440]\n",
      "loss: 0.362228  [25728/166440]\n",
      "loss: 0.315517  [38528/166440]\n",
      "loss: 0.360723  [51328/166440]\n",
      "loss: 0.414383  [64128/166440]\n",
      "loss: 0.463107  [76928/166440]\n",
      "loss: 0.366968  [89728/166440]\n",
      "loss: 0.318717  [102528/166440]\n",
      "loss: 0.412827  [115328/166440]\n",
      "loss: 0.353064  [128128/166440]\n",
      "loss: 0.383943  [140928/166440]\n",
      "loss: 0.365171  [153728/166440]\n",
      "loss: 0.241760  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.342285 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.389422  [  128/166440]\n",
      "loss: 0.391728  [12928/166440]\n",
      "loss: 0.333969  [25728/166440]\n",
      "loss: 0.317797  [38528/166440]\n",
      "loss: 0.341623  [51328/166440]\n",
      "loss: 0.422064  [64128/166440]\n",
      "loss: 0.436530  [76928/166440]\n",
      "loss: 0.358698  [89728/166440]\n",
      "loss: 0.320235  [102528/166440]\n",
      "loss: 0.400340  [115328/166440]\n",
      "loss: 0.348900  [128128/166440]\n",
      "loss: 0.392140  [140928/166440]\n",
      "loss: 0.353296  [153728/166440]\n",
      "loss: 0.252823  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.338334 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.387670  [  128/166440]\n",
      "loss: 0.387306  [12928/166440]\n",
      "loss: 0.322181  [25728/166440]\n",
      "loss: 0.308805  [38528/166440]\n",
      "loss: 0.323983  [51328/166440]\n",
      "loss: 0.431347  [64128/166440]\n",
      "loss: 0.429311  [76928/166440]\n",
      "loss: 0.352633  [89728/166440]\n",
      "loss: 0.325334  [102528/166440]\n",
      "loss: 0.388610  [115328/166440]\n",
      "loss: 0.352360  [128128/166440]\n",
      "loss: 0.392138  [140928/166440]\n",
      "loss: 0.343755  [153728/166440]\n",
      "loss: 0.252875  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.336869 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.391031  [  128/166440]\n",
      "loss: 0.389139  [12928/166440]\n",
      "loss: 0.324114  [25728/166440]\n",
      "loss: 0.301308  [38528/166440]\n",
      "loss: 0.323105  [51328/166440]\n",
      "loss: 0.431942  [64128/166440]\n",
      "loss: 0.422853  [76928/166440]\n",
      "loss: 0.355110  [89728/166440]\n",
      "loss: 0.326447  [102528/166440]\n",
      "loss: 0.386672  [115328/166440]\n",
      "loss: 0.354420  [128128/166440]\n",
      "loss: 0.389147  [140928/166440]\n",
      "loss: 0.344841  [153728/166440]\n",
      "loss: 0.250832  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.336486 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.392636  [  128/166440]\n",
      "loss: 0.388888  [12928/166440]\n",
      "loss: 0.325404  [25728/166440]\n",
      "loss: 0.298463  [38528/166440]\n",
      "loss: 0.323539  [51328/166440]\n",
      "loss: 0.431204  [64128/166440]\n",
      "loss: 0.423753  [76928/166440]\n",
      "loss: 0.354804  [89728/166440]\n",
      "loss: 0.327968  [102528/166440]\n",
      "loss: 0.384680  [115328/166440]\n",
      "loss: 0.357819  [128128/166440]\n",
      "loss: 0.387945  [140928/166440]\n",
      "loss: 0.348128  [153728/166440]\n",
      "loss: 0.246704  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.336188 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.390670  [  128/166440]\n",
      "loss: 0.389666  [12928/166440]\n",
      "loss: 0.326038  [25728/166440]\n",
      "loss: 0.296751  [38528/166440]\n",
      "loss: 0.323662  [51328/166440]\n",
      "loss: 0.430468  [64128/166440]\n",
      "loss: 0.425088  [76928/166440]\n",
      "loss: 0.355056  [89728/166440]\n",
      "loss: 0.327582  [102528/166440]\n",
      "loss: 0.383349  [115328/166440]\n",
      "loss: 0.358485  [128128/166440]\n",
      "loss: 0.387035  [140928/166440]\n",
      "loss: 0.349811  [153728/166440]\n",
      "loss: 0.246509  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.336065 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.389239  [  128/166440]\n",
      "loss: 0.389078  [12928/166440]\n",
      "loss: 0.325445  [25728/166440]\n",
      "loss: 0.297182  [38528/166440]\n",
      "loss: 0.323061  [51328/166440]\n",
      "loss: 0.428573  [64128/166440]\n",
      "loss: 0.426022  [76928/166440]\n",
      "loss: 0.356085  [89728/166440]\n",
      "loss: 0.327733  [102528/166440]\n",
      "loss: 0.381786  [115328/166440]\n",
      "loss: 0.356643  [128128/166440]\n",
      "loss: 0.386600  [140928/166440]\n",
      "loss: 0.350863  [153728/166440]\n",
      "loss: 0.244832  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.335828 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.387321  [  128/166440]\n",
      "loss: 0.388892  [12928/166440]\n",
      "loss: 0.324698  [25728/166440]\n",
      "loss: 0.297337  [38528/166440]\n",
      "loss: 0.322326  [51328/166440]\n",
      "loss: 0.425852  [64128/166440]\n",
      "loss: 0.427284  [76928/166440]\n",
      "loss: 0.357112  [89728/166440]\n",
      "loss: 0.327885  [102528/166440]\n",
      "loss: 0.381130  [115328/166440]\n",
      "loss: 0.356690  [128128/166440]\n",
      "loss: 0.387262  [140928/166440]\n",
      "loss: 0.352647  [153728/166440]\n",
      "loss: 0.242322  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.335542 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.387786  [  128/166440]\n",
      "loss: 0.388018  [12928/166440]\n",
      "loss: 0.324488  [25728/166440]\n",
      "loss: 0.297092  [38528/166440]\n",
      "loss: 0.322228  [51328/166440]\n",
      "loss: 0.424733  [64128/166440]\n",
      "loss: 0.428875  [76928/166440]\n",
      "loss: 0.357437  [89728/166440]\n",
      "loss: 0.328521  [102528/166440]\n",
      "loss: 0.381252  [115328/166440]\n",
      "loss: 0.355400  [128128/166440]\n",
      "loss: 0.387761  [140928/166440]\n",
      "loss: 0.353258  [153728/166440]\n",
      "loss: 0.242039  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.335465 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.387517  [  128/166440]\n",
      "loss: 0.389486  [12928/166440]\n",
      "loss: 0.324796  [25728/166440]\n",
      "loss: 0.298058  [38528/166440]\n",
      "loss: 0.322027  [51328/166440]\n",
      "loss: 0.423435  [64128/166440]\n",
      "loss: 0.428751  [76928/166440]\n",
      "loss: 0.357279  [89728/166440]\n",
      "loss: 0.327869  [102528/166440]\n",
      "loss: 0.381334  [115328/166440]\n",
      "loss: 0.354859  [128128/166440]\n",
      "loss: 0.387591  [140928/166440]\n",
      "loss: 0.354673  [153728/166440]\n",
      "loss: 0.239643  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.335503 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.386227  [  128/166440]\n",
      "loss: 0.390123  [12928/166440]\n",
      "loss: 0.324874  [25728/166440]\n",
      "loss: 0.298607  [38528/166440]\n",
      "loss: 0.322434  [51328/166440]\n",
      "loss: 0.422540  [64128/166440]\n",
      "loss: 0.429913  [76928/166440]\n",
      "loss: 0.356883  [89728/166440]\n",
      "loss: 0.328645  [102528/166440]\n",
      "loss: 0.381278  [115328/166440]\n",
      "loss: 0.355333  [128128/166440]\n",
      "loss: 0.388481  [140928/166440]\n",
      "loss: 0.355120  [153728/166440]\n",
      "loss: 0.239215  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.335490 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.386920  [  128/166440]\n",
      "loss: 0.389662  [12928/166440]\n",
      "loss: 0.325762  [25728/166440]\n",
      "loss: 0.298701  [38528/166440]\n",
      "loss: 0.321235  [51328/166440]\n",
      "loss: 0.422302  [64128/166440]\n",
      "loss: 0.429138  [76928/166440]\n",
      "loss: 0.356995  [89728/166440]\n",
      "loss: 0.328664  [102528/166440]\n",
      "loss: 0.381113  [115328/166440]\n",
      "loss: 0.355186  [128128/166440]\n",
      "loss: 0.388227  [140928/166440]\n",
      "loss: 0.355448  [153728/166440]\n",
      "loss: 0.237761  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.335454 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.386594  [  128/166440]\n",
      "loss: 0.390345  [12928/166440]\n",
      "loss: 0.325407  [25728/166440]\n",
      "loss: 0.299382  [38528/166440]\n",
      "loss: 0.321011  [51328/166440]\n",
      "loss: 0.421840  [64128/166440]\n",
      "loss: 0.430021  [76928/166440]\n",
      "loss: 0.359666  [89728/166440]\n",
      "loss: 0.328306  [102528/166440]\n",
      "loss: 0.380902  [115328/166440]\n",
      "loss: 0.354515  [128128/166440]\n",
      "loss: 0.388540  [140928/166440]\n",
      "loss: 0.355134  [153728/166440]\n",
      "loss: 0.238238  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.335404 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.387014  [  128/166440]\n",
      "loss: 0.390355  [12928/166440]\n",
      "loss: 0.325637  [25728/166440]\n",
      "loss: 0.299450  [38528/166440]\n",
      "loss: 0.321121  [51328/166440]\n",
      "loss: 0.420675  [64128/166440]\n",
      "loss: 0.428562  [76928/166440]\n",
      "loss: 0.356856  [89728/166440]\n",
      "loss: 0.328145  [102528/166440]\n",
      "loss: 0.380131  [115328/166440]\n",
      "loss: 0.354904  [128128/166440]\n",
      "loss: 0.387680  [140928/166440]\n",
      "loss: 0.355730  [153728/166440]\n",
      "loss: 0.237793  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.335349 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.386596  [  128/166440]\n",
      "loss: 0.390157  [12928/166440]\n",
      "loss: 0.325954  [25728/166440]\n",
      "loss: 0.299123  [38528/166440]\n",
      "loss: 0.320705  [51328/166440]\n",
      "loss: 0.420948  [64128/166440]\n",
      "loss: 0.429226  [76928/166440]\n",
      "loss: 0.357355  [89728/166440]\n",
      "loss: 0.327825  [102528/166440]\n",
      "loss: 0.379561  [115328/166440]\n",
      "loss: 0.354939  [128128/166440]\n",
      "loss: 0.388239  [140928/166440]\n",
      "loss: 0.355210  [153728/166440]\n",
      "loss: 0.237428  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.335243 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.386315  [  128/166440]\n",
      "loss: 0.389464  [12928/166440]\n",
      "loss: 0.326795  [25728/166440]\n",
      "loss: 0.299254  [38528/166440]\n",
      "loss: 0.320808  [51328/166440]\n",
      "loss: 0.420065  [64128/166440]\n",
      "loss: 0.428946  [76928/166440]\n",
      "loss: 0.357681  [89728/166440]\n",
      "loss: 0.327969  [102528/166440]\n",
      "loss: 0.378503  [115328/166440]\n",
      "loss: 0.354626  [128128/166440]\n",
      "loss: 0.387091  [140928/166440]\n",
      "loss: 0.355991  [153728/166440]\n",
      "loss: 0.237148  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.335181 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.386240  [  128/166440]\n",
      "loss: 0.389809  [12928/166440]\n",
      "loss: 0.328073  [25728/166440]\n",
      "loss: 0.300167  [38528/166440]\n",
      "loss: 0.319915  [51328/166440]\n",
      "loss: 0.419319  [64128/166440]\n",
      "loss: 0.430730  [76928/166440]\n",
      "loss: 0.356991  [89728/166440]\n",
      "loss: 0.328989  [102528/166440]\n",
      "loss: 0.377172  [115328/166440]\n",
      "loss: 0.353922  [128128/166440]\n",
      "loss: 0.388270  [140928/166440]\n",
      "loss: 0.355368  [153728/166440]\n",
      "loss: 0.235562  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.335241 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.386401  [  128/166440]\n",
      "loss: 0.390104  [12928/166440]\n",
      "loss: 0.328919  [25728/166440]\n",
      "loss: 0.300572  [38528/166440]\n",
      "loss: 0.318866  [51328/166440]\n",
      "loss: 0.418092  [64128/166440]\n",
      "loss: 0.430797  [76928/166440]\n",
      "loss: 0.357395  [89728/166440]\n",
      "loss: 0.329059  [102528/166440]\n",
      "loss: 0.375808  [115328/166440]\n",
      "loss: 0.353382  [128128/166440]\n",
      "loss: 0.389417  [140928/166440]\n",
      "loss: 0.355501  [153728/166440]\n",
      "loss: 0.234933  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.335175 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.386480  [  128/166440]\n",
      "loss: 0.390330  [12928/166440]\n",
      "loss: 0.330338  [25728/166440]\n",
      "loss: 0.301010  [38528/166440]\n",
      "loss: 0.318039  [51328/166440]\n",
      "loss: 0.416997  [64128/166440]\n",
      "loss: 0.430018  [76928/166440]\n",
      "loss: 0.357383  [89728/166440]\n",
      "loss: 0.330559  [102528/166440]\n",
      "loss: 0.374331  [115328/166440]\n",
      "loss: 0.352832  [128128/166440]\n",
      "loss: 0.389151  [140928/166440]\n",
      "loss: 0.355281  [153728/166440]\n",
      "loss: 0.233302  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334976 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.386607  [  128/166440]\n",
      "loss: 0.391848  [12928/166440]\n",
      "loss: 0.330185  [25728/166440]\n",
      "loss: 0.301855  [38528/166440]\n",
      "loss: 0.316889  [51328/166440]\n",
      "loss: 0.414927  [64128/166440]\n",
      "loss: 0.429475  [76928/166440]\n",
      "loss: 0.357275  [89728/166440]\n",
      "loss: 0.331440  [102528/166440]\n",
      "loss: 0.373139  [115328/166440]\n",
      "loss: 0.352262  [128128/166440]\n",
      "loss: 0.389113  [140928/166440]\n",
      "loss: 0.353408  [153728/166440]\n",
      "loss: 0.231436  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334879 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.387012  [  128/166440]\n",
      "loss: 0.392750  [12928/166440]\n",
      "loss: 0.329606  [25728/166440]\n",
      "loss: 0.302593  [38528/166440]\n",
      "loss: 0.316914  [51328/166440]\n",
      "loss: 0.413254  [64128/166440]\n",
      "loss: 0.430563  [76928/166440]\n",
      "loss: 0.355844  [89728/166440]\n",
      "loss: 0.333193  [102528/166440]\n",
      "loss: 0.373108  [115328/166440]\n",
      "loss: 0.353104  [128128/166440]\n",
      "loss: 0.387625  [140928/166440]\n",
      "loss: 0.352884  [153728/166440]\n",
      "loss: 0.231513  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334557 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.387775  [  128/166440]\n",
      "loss: 0.393330  [12928/166440]\n",
      "loss: 0.329607  [25728/166440]\n",
      "loss: 0.303164  [38528/166440]\n",
      "loss: 0.317473  [51328/166440]\n",
      "loss: 0.414949  [64128/166440]\n",
      "loss: 0.427779  [76928/166440]\n",
      "loss: 0.356045  [89728/166440]\n",
      "loss: 0.333171  [102528/166440]\n",
      "loss: 0.373766  [115328/166440]\n",
      "loss: 0.353121  [128128/166440]\n",
      "loss: 0.388728  [140928/166440]\n",
      "loss: 0.351747  [153728/166440]\n",
      "loss: 0.232249  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334379 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.388576  [  128/166440]\n",
      "loss: 0.393341  [12928/166440]\n",
      "loss: 0.330219  [25728/166440]\n",
      "loss: 0.303449  [38528/166440]\n",
      "loss: 0.316847  [51328/166440]\n",
      "loss: 0.414262  [64128/166440]\n",
      "loss: 0.426210  [76928/166440]\n",
      "loss: 0.354054  [89728/166440]\n",
      "loss: 0.334240  [102528/166440]\n",
      "loss: 0.373106  [115328/166440]\n",
      "loss: 0.353375  [128128/166440]\n",
      "loss: 0.388447  [140928/166440]\n",
      "loss: 0.351524  [153728/166440]\n",
      "loss: 0.230763  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334512 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.388338  [  128/166440]\n",
      "loss: 0.394032  [12928/166440]\n",
      "loss: 0.330125  [25728/166440]\n",
      "loss: 0.303603  [38528/166440]\n",
      "loss: 0.316845  [51328/166440]\n",
      "loss: 0.414006  [64128/166440]\n",
      "loss: 0.425278  [76928/166440]\n",
      "loss: 0.353642  [89728/166440]\n",
      "loss: 0.333851  [102528/166440]\n",
      "loss: 0.372662  [115328/166440]\n",
      "loss: 0.352939  [128128/166440]\n",
      "loss: 0.389076  [140928/166440]\n",
      "loss: 0.350239  [153728/166440]\n",
      "loss: 0.231129  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334446 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.388119  [  128/166440]\n",
      "loss: 0.394987  [12928/166440]\n",
      "loss: 0.329791  [25728/166440]\n",
      "loss: 0.303638  [38528/166440]\n",
      "loss: 0.316210  [51328/166440]\n",
      "loss: 0.413569  [64128/166440]\n",
      "loss: 0.425190  [76928/166440]\n",
      "loss: 0.353348  [89728/166440]\n",
      "loss: 0.334505  [102528/166440]\n",
      "loss: 0.372375  [115328/166440]\n",
      "loss: 0.352807  [128128/166440]\n",
      "loss: 0.389577  [140928/166440]\n",
      "loss: 0.350093  [153728/166440]\n",
      "loss: 0.231848  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334422 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.388682  [  128/166440]\n",
      "loss: 0.395138  [12928/166440]\n",
      "loss: 0.330164  [25728/166440]\n",
      "loss: 0.303759  [38528/166440]\n",
      "loss: 0.316071  [51328/166440]\n",
      "loss: 0.412548  [64128/166440]\n",
      "loss: 0.425644  [76928/166440]\n",
      "loss: 0.353879  [89728/166440]\n",
      "loss: 0.334261  [102528/166440]\n",
      "loss: 0.372011  [115328/166440]\n",
      "loss: 0.352597  [128128/166440]\n",
      "loss: 0.389367  [140928/166440]\n",
      "loss: 0.350596  [153728/166440]\n",
      "loss: 0.231550  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.334310 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.388012  [  128/166440]\n",
      "loss: 0.395490  [12928/166440]\n",
      "loss: 0.329819  [25728/166440]\n",
      "loss: 0.303898  [38528/166440]\n",
      "loss: 0.316521  [51328/166440]\n",
      "loss: 0.412258  [64128/166440]\n",
      "loss: 0.424909  [76928/166440]\n",
      "loss: 0.354586  [89728/166440]\n",
      "loss: 0.333687  [102528/166440]\n",
      "loss: 0.371332  [115328/166440]\n",
      "loss: 0.352301  [128128/166440]\n",
      "loss: 0.389629  [140928/166440]\n",
      "loss: 0.350222  [153728/166440]\n",
      "loss: 0.232470  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334252 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.387696  [  128/166440]\n",
      "loss: 0.396370  [12928/166440]\n",
      "loss: 0.329916  [25728/166440]\n",
      "loss: 0.304351  [38528/166440]\n",
      "loss: 0.316283  [51328/166440]\n",
      "loss: 0.411426  [64128/166440]\n",
      "loss: 0.425197  [76928/166440]\n",
      "loss: 0.354125  [89728/166440]\n",
      "loss: 0.334030  [102528/166440]\n",
      "loss: 0.371193  [115328/166440]\n",
      "loss: 0.352688  [128128/166440]\n",
      "loss: 0.388675  [140928/166440]\n",
      "loss: 0.350648  [153728/166440]\n",
      "loss: 0.230900  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334408 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.387891  [  128/166440]\n",
      "loss: 0.396294  [12928/166440]\n",
      "loss: 0.330430  [25728/166440]\n",
      "loss: 0.304405  [38528/166440]\n",
      "loss: 0.316211  [51328/166440]\n",
      "loss: 0.411206  [64128/166440]\n",
      "loss: 0.425321  [76928/166440]\n",
      "loss: 0.354339  [89728/166440]\n",
      "loss: 0.333843  [102528/166440]\n",
      "loss: 0.370961  [115328/166440]\n",
      "loss: 0.352895  [128128/166440]\n",
      "loss: 0.388876  [140928/166440]\n",
      "loss: 0.350143  [153728/166440]\n",
      "loss: 0.232489  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334344 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.387381  [  128/166440]\n",
      "loss: 0.396376  [12928/166440]\n",
      "loss: 0.330431  [25728/166440]\n",
      "loss: 0.304221  [38528/166440]\n",
      "loss: 0.316847  [51328/166440]\n",
      "loss: 0.410814  [64128/166440]\n",
      "loss: 0.425695  [76928/166440]\n",
      "loss: 0.354284  [89728/166440]\n",
      "loss: 0.335654  [102528/166440]\n",
      "loss: 0.371171  [115328/166440]\n",
      "loss: 0.352685  [128128/166440]\n",
      "loss: 0.389056  [140928/166440]\n",
      "loss: 0.350613  [153728/166440]\n",
      "loss: 0.231257  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334373 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.387947  [  128/166440]\n",
      "loss: 0.397006  [12928/166440]\n",
      "loss: 0.330847  [25728/166440]\n",
      "loss: 0.304462  [38528/166440]\n",
      "loss: 0.316249  [51328/166440]\n",
      "loss: 0.409583  [64128/166440]\n",
      "loss: 0.425730  [76928/166440]\n",
      "loss: 0.354295  [89728/166440]\n",
      "loss: 0.335678  [102528/166440]\n",
      "loss: 0.371469  [115328/166440]\n",
      "loss: 0.352399  [128128/166440]\n",
      "loss: 0.388995  [140928/166440]\n",
      "loss: 0.350962  [153728/166440]\n",
      "loss: 0.231028  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334415 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.387931  [  128/166440]\n",
      "loss: 0.397003  [12928/166440]\n",
      "loss: 0.331058  [25728/166440]\n",
      "loss: 0.304814  [38528/166440]\n",
      "loss: 0.316381  [51328/166440]\n",
      "loss: 0.409721  [64128/166440]\n",
      "loss: 0.425616  [76928/166440]\n",
      "loss: 0.354924  [89728/166440]\n",
      "loss: 0.336498  [102528/166440]\n",
      "loss: 0.371355  [115328/166440]\n",
      "loss: 0.352580  [128128/166440]\n",
      "loss: 0.389061  [140928/166440]\n",
      "loss: 0.350774  [153728/166440]\n",
      "loss: 0.230388  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334412 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.387885  [  128/166440]\n",
      "loss: 0.398041  [12928/166440]\n",
      "loss: 0.331843  [25728/166440]\n",
      "loss: 0.304837  [38528/166440]\n",
      "loss: 0.316351  [51328/166440]\n",
      "loss: 0.407699  [64128/166440]\n",
      "loss: 0.426118  [76928/166440]\n",
      "loss: 0.354784  [89728/166440]\n",
      "loss: 0.336289  [102528/166440]\n",
      "loss: 0.371070  [115328/166440]\n",
      "loss: 0.352522  [128128/166440]\n",
      "loss: 0.389167  [140928/166440]\n",
      "loss: 0.350357  [153728/166440]\n",
      "loss: 0.232231  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334274 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.388658  [  128/166440]\n",
      "loss: 0.398203  [12928/166440]\n",
      "loss: 0.331611  [25728/166440]\n",
      "loss: 0.304954  [38528/166440]\n",
      "loss: 0.316954  [51328/166440]\n",
      "loss: 0.408636  [64128/166440]\n",
      "loss: 0.426440  [76928/166440]\n",
      "loss: 0.355021  [89728/166440]\n",
      "loss: 0.336152  [102528/166440]\n",
      "loss: 0.371419  [115328/166440]\n",
      "loss: 0.352440  [128128/166440]\n",
      "loss: 0.389388  [140928/166440]\n",
      "loss: 0.349662  [153728/166440]\n",
      "loss: 0.232332  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334267 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.389142  [  128/166440]\n",
      "loss: 0.397937  [12928/166440]\n",
      "loss: 0.330969  [25728/166440]\n",
      "loss: 0.305078  [38528/166440]\n",
      "loss: 0.317644  [51328/166440]\n",
      "loss: 0.408107  [64128/166440]\n",
      "loss: 0.424731  [76928/166440]\n",
      "loss: 0.354850  [89728/166440]\n",
      "loss: 0.336118  [102528/166440]\n",
      "loss: 0.371544  [115328/166440]\n",
      "loss: 0.352415  [128128/166440]\n",
      "loss: 0.389514  [140928/166440]\n",
      "loss: 0.349886  [153728/166440]\n",
      "loss: 0.232085  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334263 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.389652  [  128/166440]\n",
      "loss: 0.397445  [12928/166440]\n",
      "loss: 0.331088  [25728/166440]\n",
      "loss: 0.305162  [38528/166440]\n",
      "loss: 0.317762  [51328/166440]\n",
      "loss: 0.407404  [64128/166440]\n",
      "loss: 0.426945  [76928/166440]\n",
      "loss: 0.354894  [89728/166440]\n",
      "loss: 0.335361  [102528/166440]\n",
      "loss: 0.371246  [115328/166440]\n",
      "loss: 0.352435  [128128/166440]\n",
      "loss: 0.389523  [140928/166440]\n",
      "loss: 0.350622  [153728/166440]\n",
      "loss: 0.231681  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334309 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.389582  [  128/166440]\n",
      "loss: 0.397547  [12928/166440]\n",
      "loss: 0.331263  [25728/166440]\n",
      "loss: 0.305202  [38528/166440]\n",
      "loss: 0.316844  [51328/166440]\n",
      "loss: 0.405912  [64128/166440]\n",
      "loss: 0.426871  [76928/166440]\n",
      "loss: 0.355370  [89728/166440]\n",
      "loss: 0.334634  [102528/166440]\n",
      "loss: 0.371691  [115328/166440]\n",
      "loss: 0.352327  [128128/166440]\n",
      "loss: 0.389930  [140928/166440]\n",
      "loss: 0.350104  [153728/166440]\n",
      "loss: 0.231396  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334293 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.389753  [  128/166440]\n",
      "loss: 0.401640  [12928/166440]\n",
      "loss: 0.330178  [25728/166440]\n",
      "loss: 0.308192  [38528/166440]\n",
      "loss: 0.318282  [51328/166440]\n",
      "loss: 0.405131  [64128/166440]\n",
      "loss: 0.422092  [76928/166440]\n",
      "loss: 0.353502  [89728/166440]\n",
      "loss: 0.332039  [102528/166440]\n",
      "loss: 0.367380  [115328/166440]\n",
      "loss: 0.348816  [128128/166440]\n",
      "loss: 0.386817  [140928/166440]\n",
      "loss: 0.350182  [153728/166440]\n",
      "loss: 0.242274  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334304 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.402951  [  128/166440]\n",
      "loss: 0.401709  [12928/166440]\n",
      "loss: 0.329458  [25728/166440]\n",
      "loss: 0.308387  [38528/166440]\n",
      "loss: 0.318039  [51328/166440]\n",
      "loss: 0.404936  [64128/166440]\n",
      "loss: 0.422503  [76928/166440]\n",
      "loss: 0.353862  [89728/166440]\n",
      "loss: 0.331841  [102528/166440]\n",
      "loss: 0.367655  [115328/166440]\n",
      "loss: 0.348706  [128128/166440]\n",
      "loss: 0.386915  [140928/166440]\n",
      "loss: 0.349527  [153728/166440]\n",
      "loss: 0.242049  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334232 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.402919  [  128/166440]\n",
      "loss: 0.400970  [12928/166440]\n",
      "loss: 0.328866  [25728/166440]\n",
      "loss: 0.308637  [38528/166440]\n",
      "loss: 0.317596  [51328/166440]\n",
      "loss: 0.404213  [64128/166440]\n",
      "loss: 0.423158  [76928/166440]\n",
      "loss: 0.353981  [89728/166440]\n",
      "loss: 0.332050  [102528/166440]\n",
      "loss: 0.367733  [115328/166440]\n",
      "loss: 0.348452  [128128/166440]\n",
      "loss: 0.387028  [140928/166440]\n",
      "loss: 0.349662  [153728/166440]\n",
      "loss: 0.241949  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334213 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.402819  [  128/166440]\n",
      "loss: 0.401205  [12928/166440]\n",
      "loss: 0.328662  [25728/166440]\n",
      "loss: 0.308966  [38528/166440]\n",
      "loss: 0.317653  [51328/166440]\n",
      "loss: 0.403909  [64128/166440]\n",
      "loss: 0.423272  [76928/166440]\n",
      "loss: 0.353779  [89728/166440]\n",
      "loss: 0.332055  [102528/166440]\n",
      "loss: 0.367683  [115328/166440]\n",
      "loss: 0.348413  [128128/166440]\n",
      "loss: 0.386991  [140928/166440]\n",
      "loss: 0.348803  [153728/166440]\n",
      "loss: 0.242035  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334179 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.402283  [  128/166440]\n",
      "loss: 0.401096  [12928/166440]\n",
      "loss: 0.328221  [25728/166440]\n",
      "loss: 0.308972  [38528/166440]\n",
      "loss: 0.317657  [51328/166440]\n",
      "loss: 0.403550  [64128/166440]\n",
      "loss: 0.422722  [76928/166440]\n",
      "loss: 0.353463  [89728/166440]\n",
      "loss: 0.331614  [102528/166440]\n",
      "loss: 0.367286  [115328/166440]\n",
      "loss: 0.348459  [128128/166440]\n",
      "loss: 0.387335  [140928/166440]\n",
      "loss: 0.349462  [153728/166440]\n",
      "loss: 0.242100  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334200 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.402565  [  128/166440]\n",
      "loss: 0.401184  [12928/166440]\n",
      "loss: 0.328085  [25728/166440]\n",
      "loss: 0.309049  [38528/166440]\n",
      "loss: 0.317267  [51328/166440]\n",
      "loss: 0.403043  [64128/166440]\n",
      "loss: 0.423335  [76928/166440]\n",
      "loss: 0.353526  [89728/166440]\n",
      "loss: 0.331542  [102528/166440]\n",
      "loss: 0.367307  [115328/166440]\n",
      "loss: 0.348389  [128128/166440]\n",
      "loss: 0.387414  [140928/166440]\n",
      "loss: 0.349026  [153728/166440]\n",
      "loss: 0.242952  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334166 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.402504  [  128/166440]\n",
      "loss: 0.401425  [12928/166440]\n",
      "loss: 0.327987  [25728/166440]\n",
      "loss: 0.309087  [38528/166440]\n",
      "loss: 0.317589  [51328/166440]\n",
      "loss: 0.403524  [64128/166440]\n",
      "loss: 0.423121  [76928/166440]\n",
      "loss: 0.353311  [89728/166440]\n",
      "loss: 0.331338  [102528/166440]\n",
      "loss: 0.366885  [115328/166440]\n",
      "loss: 0.348371  [128128/166440]\n",
      "loss: 0.387545  [140928/166440]\n",
      "loss: 0.349059  [153728/166440]\n",
      "loss: 0.243210  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334155 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.401749  [  128/166440]\n",
      "loss: 0.401524  [12928/166440]\n",
      "loss: 0.327516  [25728/166440]\n",
      "loss: 0.309121  [38528/166440]\n",
      "loss: 0.317774  [51328/166440]\n",
      "loss: 0.403538  [64128/166440]\n",
      "loss: 0.423131  [76928/166440]\n",
      "loss: 0.353405  [89728/166440]\n",
      "loss: 0.331366  [102528/166440]\n",
      "loss: 0.367106  [115328/166440]\n",
      "loss: 0.348206  [128128/166440]\n",
      "loss: 0.387529  [140928/166440]\n",
      "loss: 0.348591  [153728/166440]\n",
      "loss: 0.243118  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334137 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.401703  [  128/166440]\n",
      "loss: 0.401681  [12928/166440]\n",
      "loss: 0.327344  [25728/166440]\n",
      "loss: 0.308986  [38528/166440]\n",
      "loss: 0.317505  [51328/166440]\n",
      "loss: 0.403036  [64128/166440]\n",
      "loss: 0.423563  [76928/166440]\n",
      "loss: 0.353494  [89728/166440]\n",
      "loss: 0.331125  [102528/166440]\n",
      "loss: 0.367132  [115328/166440]\n",
      "loss: 0.348236  [128128/166440]\n",
      "loss: 0.387424  [140928/166440]\n",
      "loss: 0.349473  [153728/166440]\n",
      "loss: 0.243012  [52040/166440]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334146 \n",
      "\n",
      "No improvement. Breaking out of loop.\n",
      "Ya quedó.\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "best_metric = 0\n",
    "n_no_improve = 0\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, criterion, optimizer)\n",
    "    tuning_metric = test(test_dataloader, model, criterion)\n",
    "    \n",
    "    # Update the scheduler\n",
    "    scheduler.step(tuning_metric)\n",
    "    \n",
    "    # Save model checkpoint\n",
    "    is_best = tuning_metric > best_metric\n",
    "    if is_best:\n",
    "        best_metric = tuning_metric\n",
    "        n_no_improve = 0\n",
    "    else:\n",
    "        n_no_improve += 1\n",
    "    \n",
    "    save_checkpoint({\n",
    "        \"epoch\": t + 1,\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"best_metric\": best_metric,\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }, is_best, arg.savedir, \n",
    "                    filename=\"checkpoint_primerModeloGus.pth\", \n",
    "                    best_filename=\"model-best_primerModeloGus.pth\")\n",
    "    \n",
    "    if n_no_improve >= arg.patience:\n",
    "        print(\"No improvement. Breaking out of loop.\")\n",
    "        break\n",
    "    \n",
    "print(\"Ya quedó.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
