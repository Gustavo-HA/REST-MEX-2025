{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586d259e",
   "metadata": {},
   "source": [
    "## Aplicación del Mejor Modelo BETO al Set de Evaluación REST-MEX 2025\n",
    "Este notebook aplica el modelo de lenguaje BETO previamente entrenado y validado al conjunto de evaluación (test) del reto REST-MEX 2025. Se realiza la carga y preprocesamiento de los datos de test, la generación de predicciones de polaridad para cada instancia y la exportación de los resultados en el formato requerido para su entrega. El flujo asegura la reproducibilidad y facilita la integración de los resultados del modelo en la competencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fac23f",
   "metadata": {},
   "source": [
    "### Cargamos archivo de train/test limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab14edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# Ruta de lectura\n",
    "ruta = r\"C:\\Users\\uzgre\\Codes\\Python\\Ciencia de Datos\\Proyecto_final\\Rest-Mex_2025_DataSet\"\n",
    "archivo = os.path.join(ruta, \"Train_Limpio.csv\") \n",
    "\n",
    "with open(archivo, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    Data = pd.read_csv(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44e8edbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208051 entries, 0 to 208050\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Polarity      208051 non-null  float64\n",
      " 1   Town          208051 non-null  object \n",
      " 2   Region        208051 non-null  object \n",
      " 3   Type          208051 non-null  object \n",
      " 4   Texto_Leido   208051 non-null  object \n",
      " 5   Texto_Limpio  208051 non-null  object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261599d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    Divertido lugar para pasar el rato Lo pasamos ...\n",
       "11    BIEN UBICADO Fue mi primera vez en este hotel,...\n",
       "12    Asegúrate de pasear y explorar Hay un montón d...\n",
       "13    Increible Increíble, no se puede describir de ...\n",
       "14    PÉSIMA EXPERIENCIA, NADA RECOMENDABLE. Solo es...\n",
       "15    Mellow Vibe supera la multitud La playa está l...\n",
       "16    \"La ciudad de los dioses\" Ubicado al noreste d...\n",
       "17    \"Nice place\" El hotel está limpio pero te sien...\n",
       "18    Visita obligatoria en San Cristóbal! Hicimos e...\n",
       "19    Increíble Los cenotes son increíbles, el agua ...\n",
       "Name: Texto_Leido, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['Texto_Leido'][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b511f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ade2fe83a641648763474c7e65826a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/208051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uzgre\\AppData\\Local\\Temp\\ipykernel_8564\\1195260577.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7715\n",
      "F1 Macro: 0.6953\n",
      "F1 Micro: 0.7715\n",
      "F1 Weighted: 0.7780\n",
      "\n",
      "Reporte completo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7195    0.8654    0.7857      1070\n",
      "           1     0.6489    0.5452    0.5926      1139\n",
      "           2     0.7182    0.5850    0.6448      3072\n",
      "           3     0.5257    0.6743    0.5908      9073\n",
      "           4     0.8975    0.8306    0.8628     27257\n",
      "\n",
      "    accuracy                         0.7715     41611\n",
      "   macro avg     0.7020    0.7001    0.6953     41611\n",
      "weighted avg     0.7918    0.7715    0.7780     41611\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Revisamos las metricas de un chekpoint (necesario cargar el set de entrenamiento)\n",
    "from transformers import BertForSequenceClassification, BertTokenizerFast, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "# 1. Preparación del Dataset\n",
    "Data['Polarity'] = Data['Polarity'].astype(int)\n",
    "Data = Data[Data['Polarity'].isin([1, 2, 3, 4, 5])]\n",
    "Data['labels'] = Data['Polarity'] - 1  # Etiquetas 0 a 4\n",
    "\n",
    "# Convertir a Dataset de Hugging Face\n",
    "dataset = Dataset.from_pandas(Data[['Texto_Leido', 'labels']])\n",
    "\n",
    "# 2. Tokenización\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"Texto_Leido\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True)\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# 3. Separar en evaluación y entrenamiento\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "eval_dataset = dataset[\"test\"]\n",
    "\n",
    "# 4. Cargar modelo desde el checkpoint\n",
    "#model = BertForSequenceClassification.from_pretrained(\"./resultados_beto_mas_epocas/checkpoint-41612\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"./resultados_beto/checkpoint-20806\")\n",
    "\n",
    "# 5. Crear Trainer solo para evaluar\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# 6. Obtener predicciones\n",
    "predictions = trainer.predict(eval_dataset)\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# 7. Calcular métricas\n",
    "acc = accuracy_score(labels, preds)\n",
    "f1_macro = f1_score(labels, preds, average=\"macro\")\n",
    "f1_micro = f1_score(labels, preds, average=\"micro\")\n",
    "f1_weighted = f1_score(labels, preds, average=\"weighted\")\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1 Macro: {f1_macro:.4f}\")\n",
    "print(f\"F1 Micro: {f1_micro:.4f}\")\n",
    "print(f\"F1 Weighted: {f1_weighted:.4f}\")\n",
    "print(\"\\nReporte completo:\\n\")\n",
    "print(classification_report(labels, preds, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe58cf0",
   "metadata": {},
   "source": [
    "### Aplicamos el modelo al Set de prueba/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee93f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # True si está bien\n",
    "print(torch.cuda.get_device_name(0))  # Nombre de tu GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b4c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Ruta de lectura\n",
    "ruta = r\"C:\\Users\\uzgre\\Codes\\Python\\Ciencia de Datos\\Proyecto_final\\Rest-Mex_2025_DataSet\"\n",
    "archivo = os.path.join(ruta, \"Test_Limpio.csv\") \n",
    "\n",
    "# Cargar el archivo CSV de datos de test\n",
    "\n",
    "with open(archivo, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    Data_test = pd.read_csv(f)\n",
    "\n",
    "# Cargar modelo y tokenizer\n",
    "checkpoint_path = r\"C:\\Users\\uzgre\\Codes\\Python\\Ciencia de Datos\\Proyecto_final\\resultados_Polairty\\checkpoint-20806\"  # El checkpoint del mejor modelo\n",
    "# Cargar el modelo y el tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path)\n",
    "\n",
    "# Enviar a dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Tokenizar entradas\n",
    "inputs = tokenizer(\n",
    "    list(Data_test['Texto_Leido']),  # Usamos 'Texto_Leido' para la predicción\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "batch_size = 4  # Reduce el tamaño del batch\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Divide en batches más pequeños\n",
    "preds = []\n",
    "for i in range(0, len(inputs['input_ids']), batch_size):\n",
    "    batch_inputs = {k: v[i:i+batch_size] for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch_inputs)\n",
    "        batch_preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "        preds.extend(batch_preds)\n",
    "\n",
    "# Generar archivo de salida en formato .txt \n",
    "output_file = \"CorpusChristi_ID_Run.txt\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for idx, row in Data_test.iterrows():\n",
    "        instance_id = row['ID']\n",
    "        predicted_class = preds[idx] + 1  # De 0–4 a 1–5\n",
    "\n",
    "        # Línea con formato: rest-mex  ID  predicción  ciudad  categoría\n",
    "        output_line = f\"rest-mex  {instance_id}  {predicted_class}\\n\"\n",
    "        f.write(output_line)\n",
    "\n",
    "print(f\"Archivo '{output_file}' generado exitosamente.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
